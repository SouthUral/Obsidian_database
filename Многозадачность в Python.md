[[Процессы и потоки]]
[[Python]]

## Процессы в Python

Процессы в Python можно создать с помощью [exec](https://docs.python.org/3/library/os.html#os.execv) и [fork](https://docs.python.org/3/library/os.html#os.fork), а также организовать взаимодействие между ними с помощью [pipe](https://docs.python.org/3/library/os.html#os.pipe). Но гораздо удобнее работать с процессами при помощи модуля [multiprocessing](https://docs.python.org/3/library/multiprocessing.html).

Создавать процессы просто: достаточно создать объект класса `Process` и передать в него `callable`-объект, который должен запуститься в отдельном процессе — функцию, метод или объект класса, реализующий метод `__call__`.

```python
import time

from multiprocessing import Process

# Функция, которая будет работать в отдельном процессе
def printer(name):
    time.sleep(3)
    print('привет', name)
# Необходимо отделить точку входа в программу 
# При создании процесса запускается Python-интерпретатор. 
# Когда подгрузятся модули, он будет выполнять код, который находится на их уровне. 
# То есть, если убрать `if __name__ == '__main__':`, 
# процессы начнут создаваться рекурсивно,  и в итоге они создадут fork-бомбу.
# К счастью, Python не позволит запустить программу без явной точки входа, 
# и не даст уйти процессу в рекурсию. 
if __name__ == '__main__':
    # Создаём объект процесса, передав в него функцию и аргументы, с которыми он будет вызван
    p = Process(target=printer, args=('Алиса',))
    # Запускаем
    p.start()
    print('Пока выполняется процесс, съешьте ещё этих мягких французских булок да выпейте чаю ☕️ ')
    # Дождёмся выполнения процесса
    p.join()
```

Немного изменим код, чтобы убедиться, что создаём по-настоящему новый процесс с новым интерпретатором. После запуска программы понадобится второе окно терминала.
```python
import time
import os

from multiprocessing import Process


def printer(name):
    # Проверим гипотезу и увеличим время выполнения функции, чтобы процесс не завершился раньше
    time.sleep(50)
    print('привет', name)


if __name__ == '__main__':

    p = Process(target=printer, args=('Алиса',))
    p.start()
    print('Пока выполняется процесс, съешьте ещё этих мягких французских булок да выпейте чаю ☕️ ')
    # Выведем Process ID для текущего процесса и для процесса, который только что запустили
    print('Главный PID', os.getpid())
    print('Дочерний PID', p.pid)
    # Дождёмся выполнения процесса
    p.join()
```

Пока выполняется скрипт, во втором окне терминала выполните команду `ps aux | grep <pid_number>` для каждого полученного PID. Команда `ps` выводит запущенные процессы на компьютере.

Результат работы программы:
```shell
Пока выполняется процесс, съешьте ещё этих мягких французских булок да выпейте чаю ☕️

Главный PID 36711
Дочерний PID 36713
Привет, Алиса
```

Результат вызова `ps aux | grep <pid_number>`:
```shell 
# Вывод главного процесса
sk@cogitator ~> ps aux | grep 36711
sk               36721   0.0  0.0  4268324    700 s011  R+    9:02AM   0:00.00 grep --color=auto 36711
sk               36711   0.0  0.0  4284164   8384 s002  S+    9:02AM   0:00.07 /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/Resources/Python.app/Contents/MacOS/Python foo.py
# Вывод дочернего процесса
sk@cogitator ~> ps aux | grep 36713
sk               36730   0.0  0.0  4277540    720 s011  S+    9:02AM   0:00.00 grep --color=auto 36713
sk               36713   0.0  0.1  4283140   8628 s002  S+    9:02AM   0:00.05 /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/Resources/Python.app/Contents/MacOS/Python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=4, pipe_handle=6) --multiprocessing-fork
```
Обратите внимание на то, как запустились оба процесса. В первом случае программа запустилась, передав интерпретатору название файла. Во втором случае запускается интерпретатор, передав ему код на выполнение `-c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=4, pipe_handle=6)`.

С помощью флага `-c` передаём интерпретатору код, который нужно выполнить. `from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=4, pipe_handle=6)` вызывает функцию `spawn_main`, которая будет выполнять код, полученный через `pipe`.

Аргумент `pipe_handle` — это номер файл-дескриптора, через который будут читаться данные. `tracker_fd` необходим для отслеживания разделяемых между процессами ресурсов — памяти, семафора, пайпа. Всё это необходимо для корректной очистки ресурсов после завершения процессов.

Флаг `--multiprocessing-fork` означает, что он будет выполнять код, полученный через `pipe`, то есть от другого процесса. В случае из примера — от родительского.

При работе с процессами нужно помнить, что дочернему процессу можно передать объекты, которые могут быть сериализованы в массив-байт и десериализованы обратно.

Для сериализации и десериализации объектов при взаимодействии с процессами используется модуль [`pickle`](https://docs.python.org/3/library/pickle.html). К сожалению, `pickle` может работать в основном [с примитивными данными](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled) — числами, строками, словарями, функциями и другими.

В Python процессы применяют для распараллеливания тяжёлых вычислительных операций — вычисление хэшей, работа с матрицами, обработка изображений и подобными операциями. Именно в Python использование потоков для такого рода операций только усугубит производительность.

О том, как создаются процессы с помощью `fork()` и взаимодействуют друг с другом внутри с помощью `pipe()` можно почитать [в развёрнутой статье со схемами](https://ops-class.org/slides/2017-02-10-forksynch/). Несмотря на то что примеры даны на языке С, по ним будет легко понять, как использовать `fork()` и `pipe()`.

## Потоки в Python

Потоки можно создать с помощью модуля [`threading`](https://docs.python.org/3/library/threading.html).

Работа с потоками похожа на работу с процессами.

```python
import time
import os

# Вместо multiprocessing используем threading
from threading import Thread


def printer(name):
    time.sleep(3)
    print('привет', name)


# Интерфейс похож на работу с процессами
t = Thread(target=printer, args=('Алиса',))
t.start()
print('Пока выполняется процесс, съешьте ещё этих мягких французских булок да выпейте чаю ☕️ ')
# Дождёмся выполнения операции в потоке потока
t.join()
```

Потоки легковеснее процессов, имеют меньше накладных расходов, могут работать с любыми типами данных и не заставляют переживать, сможете ли вы сериализовать данные для передачи потоку.

Но в Python у них есть серьёзное ограничение — `GIL` (Global Interpreter Lock). Он позволяет работать только одному потоку внутри процесса, что снижает производительность многопоточных программ.

Зачем же нужен GIL? Управление памятью в Python — не потокобезопасное, поэтому нужна глобальная блокировка для корректного управления. Во время работы Python подсчитывает количество ссылок на объекты для корректного управления памятью. Это означает, что созданные в Python объекты имеют переменную подсчёта ссылок — refcount. В ней хранится количество всех ссылок на этот объект. Как только эта переменная становится равной нулю, память, выделенная под этот объект, освобождается.

Рассмотрим небольшой пример с подсчётом ссылок на объект.

```python
import sys

# Переменная 'a' первая ссылается на объект object()
a = object()
# Переменная 'b' вторая ссылается на объект object()
b = a
# Так как вы передаёте переменную 'a', которая ссылается на объект, аргумент функции тоже будет ссылаться на этот объект
# В итоге на объект будет указывать три ссылки
print(sys.getrefcount(a))
```

Одна из проблем, которую решает GIL, связана с тем, что в многопоточном приложении одновременно несколько потоков могут изменять значение счётчика ссылок. Это может привести к тому, что память очистится неправильно и удалится тот объект, на который ещё существует ссылка.

Счётчик ссылок можно защитить, добавив блокировки на все структуры данных, которые распространяются по нескольким потокам. В таком случае счётчик будет изменяться исключительно последовательно.

Но добавление блокировки к нескольким объектам может привести к появлению другой проблемы — взаимоблокировки или deadlocks, которая получается, если блокировка есть более чем на одном объекте. К тому же эта проблема тоже снижала бы производительность из-за многократной установки блокировки.

В итоге GIL превращает любую многопоточную программу в ~~тыкву~~ однопоточную.

Возникает вопрос: а зачем нужны потоки в Python?

Если программа в основном занята операциями ввода-вывода — запросами к сервисам, запросами к БД, чтением файлов —, то использование потоков позволит распараллелить программу. GIL не будет мешать, если поток будет выполнять операцию ввода/вывода, так как в этот момент он точно не будет менять счётчик ссылок. GIL просто передаст управление другому потоку, пока первый поток ожидает завершения операции ввода/вывода. По этой причине приложения написанные, например, на Django или Flask используют потоки для обработки запросов: приложения в основном взаимодействуют с БД и сторонними сервисами.

Про GIL можно почитать [набор слайдов](https://speakerdeck.com/dabeaz/understanding-the-python-gil) и [на питоновской Вики](https://wiki.python.org/moin/GlobalInterpreterLock).

## Состояние гонки

Состояние гонки — это ошибка проектирования многопоточного приложения, при которой его работа зависит от того, в каком порядке выполняются части кода. Это может произойти при работе с общими объектами между потоками, несмотря на то что GIL позволяет работать только одному потоку в один момент времени.

Рассмотрим простой пример обновления счётчика в нескольких потоках.

```python
import time
import os

from threading import Thread

# Глобальная переменная, которая будет изменяться из нескольких потоков
counter = 0

def increment():
    global counter
    for i in range(2000000):
        counter += int(1)

# Создание и запуск потоков
t = Thread(target=increment)
t.start()

t2 = Thread(target=increment)
t2.start()

# Дожидаемся завершения работы потоков
t.join()
t2.join()
print(counter)
```

Ожидаемый результат увеличения счётчика — 4000000. По факту результаты каждый раз разные.

```shell
sk@cogitator > python3 foo.py
2656780
sk@cogitator > python3 foo.py
2590505
sk@cogitator > python3 foo.py
2556543
sk@cogitator > python3 foo.py
2667262
sk@cogitator > python3 foo.py
2503490
```

Это происходит потому, что изменения переменной `counter` происходят не атомарно. Рассмотрим изменённую функцию `increment()`, которая выполняет внутреннюю реализацию операции `counter += 1`, чтобы увидеть в каком месте происходит «гонка».

```python
counter = 0

# Допустим, функция запущена в двух потоках
def increment():
    global counter
    for i in range(2000000):
        # Сначала в буфер копируется значение переменной counter
        # Допустим, текущее значение counter — 100
        # В обоих потоках в переменную buf запишется значение 100
        buf = counter
        # Оба потока увеличивают значение буфера и получают 101
        # Переменная buf у каждого потока своя
        buf = buf + 1
        # Оба потока сохраняют переменную buf в counter. В итоге counter будет равен 101, а не 102
        counter = buf
```

Чтобы этого избежать, необходимо синхронизировать потоки перед изменением счётчика с помощью примитива синхронизации Lock.

```python
import time
import os

from threading import Thread, Lock

counter = 0

# Объект блокировки
lock = Lock()

def increment():
    global counter
    for i in range(2000000):
        # С помощью контекстного менеджера захватываем блокировку и отпускаем, как только выходим из него
        with lock:
            counter += int(1)


t = Thread(target=increment)
t.start()

t2 = Thread(target=increment)
t2.start()

t.join()
t2.join()
print(counter)
```

## Что нужно запомнить про процессы и потоки

Достоинства процессов в Python:

- У каждого процесса своя память.
- Позволяют использовать все доступные ядра процессора.
- GIL не накладывает ограничения.
- Есть возможность прервать процесс.
- Подходит для тяжёлых вычислений.

Недостатки процессов в Python:

- IPC более сложный и имеет большие накладные расходы.
- Большое потребление памяти.

Достоинства потоков в Python:

- Более легковесные и требуют меньше памяти.
- Общая память между потоками.
- Можно запускать в потоках для параллельной работы модули, написанные на C, которые отпускают GIL.
- Подходят для операций ввода/вывода.

Недостатки потоков в Python:

- GIL не позволяет потокам работать одновременно кроме C модулей, которые отпускают GIL.
- Нет возможности прервать выполнение потока.
- Необходимо использовать примитивы синхронизации для работы с общей памятью, чтобы предотвратить «гонку».